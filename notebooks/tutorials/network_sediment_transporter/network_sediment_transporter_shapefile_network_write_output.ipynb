{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://landlab.github.io\"><img style=\"float: left\" src=\"../../landlab_header.png\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write NetCDF output of sediment parcels. \n",
    "\n",
    "<hr>\n",
    "<small>For more Landlab tutorials, click here: <a href=\"https://landlab.readthedocs.io/en/latest/user_guide/tutorials.html\">https://landlab.readthedocs.io/en/latest/user_guide/tutorials.html</a></small>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from landlab.components import FlowDirectorSteepest, NetworkSedimentTransporter\n",
    "from landlab.data_record import DataRecord\n",
    "from landlab.grid.network import NetworkModelGrid\n",
    "from landlab.plot import graph\n",
    "from landlab.io import read_shapefile\n",
    "from landlab import ExampleData\n",
    "import xarray as xr\n",
    "from landlab.plot import plot_network_and_parcels\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = ExampleData(\"io/shapefile\", case=\"methow\").base\n",
    "\n",
    "shp_file = datadir / \"MethowSubBasin.shp\"\n",
    "points_shapefile = datadir / \"MethowSubBasin_Nodes_4.shp\"\n",
    "\n",
    "grid = read_shapefile(\n",
    "    shp_file,\n",
    "    points_shapefile=points_shapefile,\n",
    "    node_fields=[\"usarea_km2\", \"Elev_m\"],\n",
    "    link_fields=[\"usarea_km2\", \"Length_m\"],\n",
    "    link_field_conversion={\"usarea_km2\": \"drainage_area\", \"Slope\":\"channel_slope\", \"Length_m\":\"reach_length\"},\n",
    "    node_field_conversion={\n",
    "        \"usarea_km2\": \"drainage_area\",\n",
    "        \"Elev_m\": \"topographic__elevation\",\n",
    "    },\n",
    "    threshold=0.01,\n",
    "    )\n",
    "grid.at_node[\"bedrock__elevation\"] = grid.at_node[\"topographic__elevation\"].copy()\n",
    "\n",
    "grid.at_link[\"channel_width\"] = 1 * np.ones(grid.number_of_links) # m\n",
    "\n",
    "grid.at_link[\"flow_depth\"] = 0.5 * np.ones(grid.number_of_links) # m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create parcels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element_id is the link on which the parcel begins. \n",
    "element_id = np.repeat(np.arange(grid.number_of_links), 10)\n",
    "element_id = np.expand_dims(element_id, axis=1)\n",
    "\n",
    "volume = 1*np.ones(np.shape(element_id))  # (m3)\n",
    "active_layer = np.ones(np.shape(element_id)) # 1= active, 0 = inactive\n",
    "density = 2650 * np.ones(np.size(element_id))  # (kg/m3)\n",
    "abrasion_rate = 0 * np.ones(np.size(element_id)) # (mass loss /m)\n",
    "\n",
    "# Lognormal GSD\n",
    "medianD = 0.15 # m\n",
    "mu = np.log(medianD)\n",
    "sigma = np.log(2) #assume that D84 = sigma*D50\n",
    "np.random.seed(0)\n",
    "D = np.random.lognormal(\n",
    "    mu,\n",
    "    sigma,\n",
    "    np.shape(element_id)\n",
    ")  # (m) the diameter of grains in each parcel\n",
    "time_arrival_in_link = np.random.rand(np.size(element_id), 1) \n",
    "location_in_link = np.random.rand(np.size(element_id), 1) \n",
    "lithology = [\"quartzite\"] * np.size(element_id)\n",
    "variables = {\n",
    "    \"abrasion_rate\": ([\"item_id\"], abrasion_rate),\n",
    "    \"density\": ([\"item_id\"], density),\n",
    "    \"lithology\": ([\"item_id\"], lithology),\n",
    "    \"time_arrival_in_link\": ([\"item_id\", \"time\"], time_arrival_in_link),\n",
    "    \"active_layer\": ([\"item_id\", \"time\"], active_layer),\n",
    "    \"location_in_link\": ([\"item_id\", \"time\"], location_in_link),\n",
    "    \"D\": ([\"item_id\", \"time\"], D),\n",
    "    \"volume\": ([\"item_id\", \"time\"], volume)\n",
    "}\n",
    "\n",
    "items = {\"grid_element\": \"link\", \"element_id\": element_id}\n",
    "\n",
    "parcels = DataRecord(\n",
    "    grid,\n",
    "    items=items,\n",
    "    time=[0.0],\n",
    "    data_vars=variables,\n",
    "    dummy_elements={\"link\": [NetworkSedimentTransporter.OUT_OF_NETWORK]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 15 # total number of timesteps\n",
    "pulse_timestep = 7\n",
    "pulse_link = 27\n",
    "dt = 60 * 60 * 24 *2 # length of timestep (seconds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pulse parcels, put them all on link 27:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_pulse_parcels = 100\n",
    "\n",
    "newpar_element_id = np.zeros(num_pulse_parcels, dtype=int) + pulse_link\n",
    "newpar_element_id = np.expand_dims(newpar_element_id, axis=1)\n",
    "\n",
    "new_starting_link = np.squeeze(newpar_element_id)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "new_time_arrival_in_link = pulse_timestep * dt * np.ones(np.shape(newpar_element_id))\n",
    "\n",
    "new_volume = 0.5 * np.ones(\n",
    "    np.shape(newpar_element_id)\n",
    ")  # (m3) the volume of each parcel\n",
    "\n",
    "new_lithology = [\"pulse_material\"] * np.size(\n",
    "    newpar_element_id\n",
    ")  # a lithology descriptor for each parcel\n",
    "\n",
    "new_active_layer = np.ones(\n",
    "    np.shape(newpar_element_id)\n",
    ")  # 1 = active/surface layer; 0 = subsurface layer\n",
    "\n",
    "new_density = 2650 * np.ones(np.size(newpar_element_id))  # (kg/m3)\n",
    "\n",
    "new_location_in_link = np.random.rand(np.size(newpar_element_id), 1)\n",
    "\n",
    "new_abrasion_rate = 0 * np.ones(np.size(newpar_element_id))\n",
    "\n",
    "new_D = 0.1 * np.ones(np.shape(newpar_element_id))\n",
    "\n",
    "# smaller lognormal GSD\n",
    "medianD = 0.1 # m\n",
    "mu = np.log(medianD)\n",
    "sigma = np.log(2) #assume that D84 = sigma*D50\n",
    "np.random.seed(0)\n",
    "new_D = np.random.lognormal(\n",
    "    mu,\n",
    "    sigma,\n",
    "    np.shape(newpar_element_id)\n",
    ")  # (m) the diameter of grains in each parcel\n",
    "\n",
    "newpar_grid_elements = np.array(\n",
    "    np.empty((np.shape(newpar_element_id)), dtype=object)\n",
    ")  # BUG: should be able to pass [\"link\"], but datarecord fills it into an incorrect array shape-- the length of parcels (NOT new parcels)\n",
    "newpar_grid_elements.fill(\"link\")\n",
    "\n",
    "new_parcels = {\n",
    "    \"grid_element\": newpar_grid_elements,\n",
    "    \"element_id\": newpar_element_id,\n",
    "}\n",
    "\n",
    "new_variables = {\n",
    "    \"starting_link\": ([\"item_id\"], new_starting_link),\n",
    "    \"abrasion_rate\": ([\"item_id\"], new_abrasion_rate),\n",
    "    \"density\": ([\"item_id\"], new_density),\n",
    "    \"lithology\": ([\"item_id\"], new_lithology),\n",
    "    \"time_arrival_in_link\": ([\"item_id\", \"time\"], new_time_arrival_in_link),\n",
    "    \"active_layer\": ([\"item_id\", \"time\"], new_active_layer),\n",
    "    \"location_in_link\": ([\"item_id\", \"time\"], new_location_in_link),\n",
    "    \"D\": ([\"item_id\", \"time\"], new_D),\n",
    "    \"volume\": ([\"item_id\", \"time\"], new_volume),\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the NST, we need to determine flow direction on the grid (upstream and downstream for each link). To do so, we initalize and run a Landlab flow director component: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FlowDirectorSteepest(grid, \"topographic__elevation\")\n",
    "fd.run_one_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we initialize the network sediment transporter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nst = NetworkSedimentTransporter(    \n",
    "    grid,\n",
    "    parcels,\n",
    "    fd,\n",
    "    bed_porosity=0.3,\n",
    "    g=9.81,\n",
    "    fluid_density=1000,\n",
    "    transport_method=\"WilcockCrowe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to run the model forward in time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for i in range(timesteps):\n",
    "    if i == pulse_timestep:\n",
    "        parcels.add_item(time=[nst.time], new_item=new_parcels, new_item_spec=new_variables)\n",
    "        \n",
    "    nst.run_one_step(dt)\n",
    "    \n",
    "    if i>1 and np.remainder(i, 5) == 4: \n",
    "        fn = \"file_{i}.nc\".format(i=i)\n",
    "        files.append(fn)\n",
    "        if i+1 == timesteps:\n",
    "            parcels.dump_prior_timesteps_to_netcdf(fn, include_final_timestep=True)\n",
    "        else:\n",
    "            parcels.dump_prior_timesteps_to_netcdf(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is now tricky, b/c plotting expects a DataRecord, not an xarray dataset. Difference is parcels.dataset vs parcels_ds.\n",
    "\n",
    "Right now I'm going to hack this by private var assignment. My suspicion is that the right thing to do would be to make it possible to make create a datarecord from grid and dataset e.g.\n",
    "\n",
    "\n",
    "```python\n",
    "grid = (recreate grid from files)\n",
    "parcels_ds = load_from_files\n",
    "parcels = DataRecord.from_grid_and_dataset(grid, parcels_ds)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parcels_ds = xr.open_mfdataset(files)\n",
    "\n",
    "dummy_elements={\"link\": [NetworkSedimentTransporter.OUT_OF_NETWORK]}\n",
    "\n",
    "parcels = DataRecord.from_grid_and_dataset(grid, parcels_ds, dummy_elements=dummy_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below is an example of accessing variables associated with the grid (`grid.at_link.X`, or `grid.at_node.X`), as well as a variable associated with this instance of NetworkModelGrid (`nmg.X`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(timesteps):\n",
    "\n",
    "    fig = plot_network_and_parcels(\n",
    "        grid, parcels,\n",
    "        parcel_time_index=i,\n",
    "        parcel_alpha = 0.6\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "for file in files:\n",
    "    os.remove(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
